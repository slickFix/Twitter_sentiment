{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2 as pg2\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.width  = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining functions\n",
    "\n",
    "def getDataFromDB(query):\n",
    "    \n",
    "    try:\n",
    "        conn = pg2.connect(dbname='twitterDB',user='postgres',password='postgres',host='localhost',port='5432')\n",
    "        \n",
    "        if conn.closed ==0:  # checks the system connection is active\n",
    "            print(\"Connected to the DB\")\n",
    "            \n",
    "            cur = conn.cursor()\n",
    "            \n",
    "            cur.execute(query)\n",
    "            records = cur.fetchall()\n",
    "            \n",
    "            print(\"Data fetched\")\n",
    "            \n",
    "            return records\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(\"Error thrown\")\n",
    "        print(e)\n",
    "    \n",
    "    finally:\n",
    "        print(\"Closing connection\")\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTweetLen(df):\n",
    "    \n",
    "    df['tweet_len'] = df['clean_tweets'].str.len()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFrame(val):\n",
    "    df = pd.DataFrame(val,columns=['index','username','time_created','tweet','retweet_count','place_tweet','location_user'])\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['tweet']\n",
    "\n",
    "\n",
    "# for i in df['tweet'][:100000]:\n",
    "#     exclusion_li = ['\\W','rt','RT','http','co']\n",
    "#     exclusion_cond = '|'.join(exclusion_li)\n",
    "#     tweet = re.sub(exclusion_cond,' ',i)\n",
    "#     tweet = tweet.lower()\n",
    "#     tweet_words = nltk.word_tokenize(tweet)  # OR USE split function\n",
    "#     wnl = nltk.WordNetLemmatizer()\n",
    "#     clean_words = [wnl.lemmatize(i) for i in tweet_words if i not in set(stopwords.words('english'))]\n",
    "#     clean_tweet = ' '.join(clean_words)\n",
    "    \n",
    "    \n",
    "# exclusion_li = ['\\W','rt','RT','http+','co']\n",
    "# exclusion_cond = '|'.join(exclusion_li)\n",
    "# s = 'Take a bow, Ms. Channing'\n",
    "# test = tweet = re.sub(exclusion_cond,' ',s)\n",
    "# test = test.lower()\n",
    "# tweet_words = nltk.word_tokenize(test)\n",
    "# wnl = nltk.WordNetLemmatizer()\n",
    "# words = [wnl.lemmatize(i) for i in tweet_words if i not in set(stopwords.words('english'))]\n",
    "# clean_test = ' '.join(words)\n",
    "# words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing tweets -> 1)removing non digits,rt,etc 2)Converting to lower \n",
    "# Tokenisation\n",
    "# Lemmatization + removing stopwords\n",
    "\n",
    "def cleanTweets(df):\n",
    "    df['clean_tweets'] = None\n",
    "    \n",
    "    for idx,i in enumerate(df['tweet']):\n",
    "        #print(idx,i)\n",
    "        exclusion_li = ['\\W','rt','RT','http','co']\n",
    "        exclusion_cond = '|'.join(exclusion_li)\n",
    "        tweet = re.sub(exclusion_cond,' ',i)\n",
    "        tweet = tweet.lower()\n",
    "        tweet_words = tweet.split()  \n",
    "        wnl = nltk.WordNetLemmatizer()\n",
    "        clean_words = [wnl.lemmatize(i) for i in tweet_words if i not in set(stopwords.words('english'))]\n",
    "        clean_tweet = ' '.join(clean_words)\n",
    "        df.loc[idx,'clean_tweets'] = clean_tweet\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working for All twitter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = 'select * from tweets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the DB\n",
      "Data fetched\n",
      "Closing connection\n"
     ]
    }
   ],
   "source": [
    "val = getDataFromDB(query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = getDataFrame(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working of fraction of the whole dataset\n",
    "\n",
    "df = df.sample(frac = 0.001,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>username</th>\n",
       "      <th>time_created</th>\n",
       "      <th>tweet</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>place_tweet</th>\n",
       "      <th>location_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7023</th>\n",
       "      <td>6991</td>\n",
       "      <td>PutraNurfajri</td>\n",
       "      <td>2019-01-16 19:12:59+05:30</td>\n",
       "      <td>Take me somewhere nice</td>\n",
       "      <td>0</td>\n",
       "      <td>Somewhere I belong to</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143339</th>\n",
       "      <td>143353</td>\n",
       "      <td>Taragolf1</td>\n",
       "      <td>2019-01-18 18:35:34+05:30</td>\n",
       "      <td>RT @SafetyPinDaily: EPA nominee Andrew Wheeler...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85435</th>\n",
       "      <td>85380</td>\n",
       "      <td>Younghoncho</td>\n",
       "      <td>2019-01-18 11:57:53+05:30</td>\n",
       "      <td>RT @RICO_RECKLEZZ: Watevas meant gon happen ü§üüèΩüíØ</td>\n",
       "      <td>0</td>\n",
       "      <td>üåè</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116382</th>\n",
       "      <td>116367</td>\n",
       "      <td>jxckmin</td>\n",
       "      <td>2019-01-18 17:12:20+05:30</td>\n",
       "      <td>RT @yoongi2seokjoon: [FREEBIES] photocard/stri...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59624</th>\n",
       "      <td>59542</td>\n",
       "      <td>b1kuta</td>\n",
       "      <td>2019-01-18 11:15:59+05:30</td>\n",
       "      <td>Oomf still dragging Ari like he won‚Äôt bust to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index       username               time_created                                              tweet  retweet_count            place_tweet location_user\n",
       "7023      6991  PutraNurfajri  2019-01-16 19:12:59+05:30                             Take me somewhere nice              0  Somewhere I belong to          None\n",
       "143339  143353      Taragolf1  2019-01-18 18:35:34+05:30  RT @SafetyPinDaily: EPA nominee Andrew Wheeler...              0                   None          None\n",
       "85435    85380    Younghoncho  2019-01-18 11:57:53+05:30    RT @RICO_RECKLEZZ: Watevas meant gon happen ü§üüèΩüíØ              0                      üåè          None\n",
       "116382  116367        jxckmin  2019-01-18 17:12:20+05:30  RT @yoongi2seokjoon: [FREEBIES] photocard/stri...              0                   None          None\n",
       "59624    59542         b1kuta  2019-01-18 11:15:59+05:30  Oomf still dragging Ari like he won‚Äôt bust to ...              0                   None          None"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop = True,inplace=True) # drop is used to remove the old indexing from adding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cleanTweets(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = addTweetLen(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>username</th>\n",
       "      <th>time_created</th>\n",
       "      <th>tweet</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>place_tweet</th>\n",
       "      <th>location_user</th>\n",
       "      <th>clean_tweets</th>\n",
       "      <th>tweet_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6991</td>\n",
       "      <td>PutraNurfajri</td>\n",
       "      <td>2019-01-16 19:12:59+05:30</td>\n",
       "      <td>Take me somewhere nice</td>\n",
       "      <td>0</td>\n",
       "      <td>Somewhere I belong to</td>\n",
       "      <td>None</td>\n",
       "      <td>take somewhere nice</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>143353</td>\n",
       "      <td>Taragolf1</td>\n",
       "      <td>2019-01-18 18:35:34+05:30</td>\n",
       "      <td>RT @SafetyPinDaily: EPA nominee Andrew Wheeler...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>safetypindaily epa nominee andrew wheeler read...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85380</td>\n",
       "      <td>Younghoncho</td>\n",
       "      <td>2019-01-18 11:57:53+05:30</td>\n",
       "      <td>RT @RICO_RECKLEZZ: Watevas meant gon happen ü§üüèΩüíØ</td>\n",
       "      <td>0</td>\n",
       "      <td>üåè</td>\n",
       "      <td>None</td>\n",
       "      <td>rico_recklezz watevas meant gon happen</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116367</td>\n",
       "      <td>jxckmin</td>\n",
       "      <td>2019-01-18 17:12:20+05:30</td>\n",
       "      <td>RT @yoongi2seokjoon: [FREEBIES] photocard/stri...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>yoongi2seokjoon freebie photocard strip polaro...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59542</td>\n",
       "      <td>b1kuta</td>\n",
       "      <td>2019-01-18 11:15:59+05:30</td>\n",
       "      <td>Oomf still dragging Ari like he won‚Äôt bust to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>oomf still dragging ari like bust later</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index       username               time_created                                              tweet  retweet_count            place_tweet location_user                                       clean_tweets  tweet_len\n",
       "0    6991  PutraNurfajri  2019-01-16 19:12:59+05:30                             Take me somewhere nice              0  Somewhere I belong to          None                                take somewhere nice         19\n",
       "1  143353      Taragolf1  2019-01-18 18:35:34+05:30  RT @SafetyPinDaily: EPA nominee Andrew Wheeler...              0                   None          None  safetypindaily epa nominee andrew wheeler read...         97\n",
       "2   85380    Younghoncho  2019-01-18 11:57:53+05:30    RT @RICO_RECKLEZZ: Watevas meant gon happen ü§üüèΩüíØ              0                      üåè          None             rico_recklezz watevas meant gon happen         38\n",
       "3  116367        jxckmin  2019-01-18 17:12:20+05:30  RT @yoongi2seokjoon: [FREEBIES] photocard/stri...              0                   None          None  yoongi2seokjoon freebie photocard strip polaro...        115\n",
       "4   59542         b1kuta  2019-01-18 11:15:59+05:30  Oomf still dragging Ari like he won‚Äôt bust to ...              0                   None          None            oomf still dragging ari like bust later         39"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
